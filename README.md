# Projet de Reconnaissance Vocale : LPC & MFCC avec k-NN et HMM

Ce projet a Ã©tÃ© rÃ©alisÃ© dans le cadre du module **"Traitement et Analyse des DonnÃ©es Visuelles et Sonores"** Ã  l'Ã‰cole Centrale de Lyon. L'objectif Ã©tait de dÃ©velopper des systÃ¨mes simples de reconnaissance de la parole en utilisant deux approches diffÃ©rentes : les **coefficients LPC (Linear Predictive Coding)** avec la mÃ©thode des **k plus proches voisins (k-NN)**, et les **coefficients MFCC (Mel-Frequency Cepstral Coefficients)** avec les **ModÃ¨les de Markov CachÃ©s (HMM)**.

---

## ğŸ“Œ AperÃ§u du Projet

L'objectif principal de ce projet Ã©tait de reconnaÃ®tre des chiffres prononcÃ©s (de 0 Ã  9) Ã  partir d'enregistrements audio. Nous avons explorÃ© deux approches distinctes pour rÃ©soudre ce problÃ¨me :

1. **Approche 1 : Coefficients LPC + k-NN**
   - Utilisation des coefficients LPC pour modÃ©liser la parole.
   - Classification avec la mÃ©thode des k plus proches voisins (k-NN) et une distance Ã©lastique pour gÃ©rer les variations de longueur des enregistrements.
   - RÃ©sultat : **50% de prÃ©cision**.

2. **Approche 2 : Coefficients MFCC + HMM**
   - Calcul des coefficients MFCC pour capturer les caractÃ©ristiques spectrales des enregistrements.
   - Utilisation de ModÃ¨les de Markov CachÃ©s (HMM) pour modÃ©liser les sÃ©quences de phonÃ¨mes.
   - Optimisation des hyperparamÃ¨tres
   - RÃ©sultat : **85.7% de prÃ©cision**
---

## ğŸš€ FonctionnalitÃ©s

- **Traitement du signal audio** : Chargement, normalisation et extraction des caractÃ©ristiques (LPC et MFCC).
- **Classification** : Utilisation de l'algorithme des k plus proches voisins (k-NN) avec une distance Ã©lastique pour la premiÃ¨re approche.
- **ModÃ©lisation** : ImplÃ©mentation de ModÃ¨les de Markov CachÃ©s (HMM) pour la reconnaissance de sÃ©quences audio.
- **Optimisation** : Utilisation de la bibliothÃ¨que `numba` pour accÃ©lÃ©rer les calculs et validation des hyperparamÃ¨tres pour amÃ©liorer les performances.

---

## ğŸ“Š RÃ©sultats

### Approche 1 : LPC + k-NN
- **PrÃ©cision** : 50%
- **Matrice de confusion** : Les chiffres 0 et 6 sont les mieux classÃ©s, tandis que les chiffres 1 et 5 sont souvent confondus.

### Approche 2 : MFCC + HMM
- **PrÃ©cision** : 85.7% (avec les hyperparamÃ¨tres optimisÃ©s)
- **Matrice de confusion** : Une amÃ©lioration significative a Ã©tÃ© observÃ©e par rapport Ã  la premiÃ¨re approche. Bien que les rÃ©sultats soient dÃ©jÃ  solides, une marge de progression existe avec davantage de temps de calcul et de donnÃ©es d'entraÃ®nement.

---

## ğŸ› ï¸ Technologies UtilisÃ©es

- **Langage** : Python
- **BibliothÃ¨ques** :
  - `librosa` pour le traitement audio.
  - `scipy` et `numpy` pour les calculs scientifiques.
  - `hmmlearn` pour les ModÃ¨les de Markov CachÃ©s.
  - `numba` pour l'accÃ©lÃ©ration des calculs.
  - `scikit-learn` pour l'Ã©valuation des performances.

---

## ğŸ“‚ Structure du Projet

projet-reconnaissance-vocale/
â”œâ”€â”€ data/ # Dossier contenant les enregistrements audio
â”œâ”€â”€ scripts/ # Scripts Python pour le traitement et la classification
â”‚ â”œâ”€â”€ lpc_knn.py # Script pour l'approche LPC + k-NN
â”‚ â”œâ”€â”€ mfcc_hmm.py # Script pour l'approche MFCC + HMM
â”‚ â””â”€â”€ utils.py # Fonctions utilitaires (chargement des donnÃ©es, dÃ©coupe du signal en frames,etc.)
â”œâ”€â”€ results/ # RÃ©sultats et visualisations (matrices de confusion, etc.)
â”œâ”€â”€ README.md # Ce fichier
â””â”€â”€ requirements.txt # DÃ©pendances du projet


---

## ğŸš€ Comment ExÃ©cuter le Projet

1. **Cloner le dÃ©pÃ´t** :
    ```bash
    git clone https://github.com/votre-utilisateur/projet-reconnaissance-vocale.git
    cd projet-reconnaissance-vocale

2. **Installer les dÃ©pendances** :

    ```bash
    pip install -r requirements.txt

3. **ExÃ©cuter les scripts** :

Pour l'approche LPC + k-NN :

    python scripts/lpc_knn.py

Pour l'approche MFCC + HMM :

    python scripts/mfcc_hmm.py


## ğŸ“ˆ AmÃ©liorations Futures

- **Base de donnÃ©es plus large** : Utiliser une base de donnÃ©es plus variÃ©e avec plus de locuteurs pour amÃ©liorer la gÃ©nÃ©ralisation du modÃ¨le.
- **ModÃ¨les de langage** : IntÃ©grer des modÃ¨les de langage statistiques ou neuronaux pour amÃ©liorer la reconnaissance des mots et des phrases.
- **Optimisation des hyperparamÃ¨tres** : Explorer davantage les hyperparamÃ¨tres des HMM (comme `n_components` et `n_iter`) et des MFCC (comme `n_mfcc`, `win_length`, et `hop_length`) pour amÃ©liorer les performances.
- **Traitement du bruit** : Ajouter des techniques de rÃ©duction du bruit pour amÃ©liorer la qualitÃ© des enregistrements audio et la robustesse du modÃ¨le.
- **IntÃ©gration de modÃ¨les modernes** : Explorer l'utilisation de rÃ©seaux de neurones profonds (RNN, LSTM, ou Transformers) pour capturer des dÃ©pendances temporelles plus complexes.
- **Interface utilisateur** : DÃ©velopper une interface utilisateur simple pour permettre Ã  des non-experts d'utiliser le systÃ¨me de reconnaissance vocale.


---

## ğŸ‘¨â€ğŸ’» Auteurs

- **RÃ©my GASMI**
- **Simon VINCENT**

---


## ğŸ™ Remerciements

Un grand merci Ã  **Emmanuel DELLANDRÃ‰A** pour son encadrement et ses prÃ©cieux conseils tout au long de ce projet.

---